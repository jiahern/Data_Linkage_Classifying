{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "import sklearn\n",
    "import re\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 - Data Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity calculation function\n",
    "def similar(a,b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "#build a function to find matching pair by blocking method\n",
    "def find_pair (limit,thrhold,bsize):\n",
    "    i = 0\n",
    "    \n",
    "    #create an empty dataframe to store the matched pairs\n",
    "    pair_find = pd.DataFrame(columns = [\"idAmazon\",\"idGoogleBase\"])\n",
    "    \n",
    "    #each loop will generate a block for amazon and google, and add the matched pairs to pair_found\n",
    "    while i<limit:\n",
    "        #generate blocks with same blocking key\n",
    "        condition_a = ((amazon[\"price\"]>=i) & (amazon[\"price\"]<=i+bsize))\n",
    "        condition_g = ((google[\"price\"]>=i) & (google[\"price\"]<=i+bsize))\n",
    "        block_a = amazon[condition_a]\n",
    "        block_g = google[condition_g]\n",
    "        pair_index_a = []\n",
    "        pair_index_g = []\n",
    "        \n",
    "        #match the records in different blocks\n",
    "        for record1 in block_a[\"title\"]:\n",
    "            for record2 in block_g[\"name\"]:\n",
    "                score = similar(record1,record2)\n",
    "                if score > thrhold:\n",
    "                    pair_index_a.append(block_a[block_a[\"title\"]==record1].idAmazon.values[0])\n",
    "                    pair_index_g.append(block_g[block_g[\"name\"]==record2].id.values[0])\n",
    "        \n",
    "        #format the matched pairs into dataframe and append to the empty dataframe\n",
    "        pairs = pd.DataFrame({'idAmazon':pair_index_a,'idGoogleBase':pair_index_g})\n",
    "        pair_found = pair_found.append(pairs, ignore_index=True)\n",
    "        i+=bsize\n",
    "    return pair_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive data linkage without blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Matches: 130\n",
      "Correctly Matched: 96\n",
      "Recall: 0.7384615384615385\n",
      "Precision: 0.7218045112781954\n"
     ]
    }
   ],
   "source": [
    "#Read in datasets\n",
    "amazon_s = pd.read_csv(\"amazon_small.csv\")\n",
    "google_s = pd.read_csv('google_small.csv')\n",
    "gt_s = pd.read_csv('amazon_google_truth_small.csv')\n",
    "\n",
    "pair_index_A = []\n",
    "pair_index_G = []\n",
    "#link the records from different datasets by attributes 'title', 'name'\n",
    "for record1 in amazon_s[\"title\"]:\n",
    "    for record2 in google_s[\"name\"]:\n",
    "        score = similar(record1,record2)\n",
    "        if score > 0.54:\n",
    "            pair_index_A.append(amazon_s[amazon_s[\"title\"]==record1].idAmazon.values[0])\n",
    "            pair_index_G.append(google_s[google_s[\"name\"]==record2].idGoogleBase.values[0])\n",
    "\n",
    "pairs = pd.DataFrame({'idAmazon':pair_index_A,'idGoogleBase':pair_index_G})\n",
    "tp_pair = pd.merge(pairs, gt_s, how='inner', on=['idAmazon','idGoogleBase'])\n",
    "\n",
    "true_match = gt_s.shape[0]\n",
    "tp = tp_pair.shape[0]\n",
    "fn = gt_s.shape[0]-tp\n",
    "fp = pairs.shape[0]-tp\n",
    "\n",
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "\n",
    "print (\"True Matches:\",true_match)\n",
    "print (\"Correctly Matched:\",tp)\n",
    "print (\"Recall:\",recall)\n",
    "print (\"Precision:\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 Na¨ıve data linkage without blocking\n",
    "\n",
    "#2. The linkage method we applied is based on the amazon_small(title) and google_small(name). This is due to there are no\n",
    "#  Null value in those attributes which may increase the accuracy of the similarity comparison. For similarity function,\n",
    "#  there are roughly three types of similarity function: Edit distance based, Token-based and Sequence-based(Pattern Search).   \n",
    "#  Among three of them, Sequence-based has the highest result. By applying Sequence-based similarity function, \n",
    "#  SequenceMatcher by difflib. The theory is based on Gestalt Pattern Matching, finding the longest common substring \n",
    "#  plus recursively the number of matching characters in the non-matching regions on both sides of the LCS. The more matching,\n",
    "#  the higher similarity score will be. The threshold(0.54) is set depends on the amount of rows of ground truth dataset. \n",
    "#  When threshold higher, the output row lesser.By using this function, it allows us to indicate the long strings in both \n",
    "#  of the attributes precisely. Overall, the performance's results are pretty presentable, recall(0.74) and precision(0.72).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocking for efficient data linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Matches: 1300\n",
      "Correctly Matched: 511\n",
      "Pair Completeness: 0.3930769230769231\n",
      "Recuction Ratio: 0.9996937705843798\n"
     ]
    }
   ],
   "source": [
    "#Read in different datasets\n",
    "google = pd.read_csv(\"google.csv\")\n",
    "amazon = pd.read_csv(\"amazon.csv\")\n",
    "gt = pd.read_csv(\"amazon_google_truth.csv\")\n",
    "\n",
    "# Data Cleaning google\n",
    "\n",
    "# convert price in google dataset, gbp pound sterling into aud \n",
    "for row in google.index:\n",
    "    if \"gbp\" in google.loc[row,\"price\"]:\n",
    "        price = google.loc[row,\"price\"]\n",
    "        google.loc[row,\"price\"] = 1.83*int(re.findall(\"\\d+\", price)[0])\n",
    "\n",
    "google['price'] = pd.to_numeric(google['price'], errors = 'coerce')\n",
    "\n",
    "# Data Cleaning amazon\n",
    "\n",
    "amazon.sort_values(\"price\")\n",
    "amazon['price'] = pd.to_numeric(amazon['price'], errors = 'coerce')\n",
    "\n",
    "#name the result as pair01\n",
    "#use 10e5 as limit since it is bigger than all price values in either amazon or google\n",
    "#after a series of attemption, decide to use 0.65 as the threshold to obtain similar size of pairs with ground truth\n",
    "pairs = find_pair(10e5,0.65,50)\n",
    "\n",
    "TP_pairs = pd.merge(pair01,gt,how=\"inner\",on=[\"idAmazon\",\"idGoogleBase\"])\n",
    "\n",
    "TP = TP_pairs.shape[0]\n",
    "FP = pair01.shape[0]-TP\n",
    "FN = gt.shape[0]-TP\n",
    "TN = amazon.shape[0]*google.shape[0]-TP\n",
    "n = TP + FP + FN + TN\n",
    "\n",
    "PC = TP/(TP+FN)\n",
    "RR = 1 - (TP+FP)/n\n",
    "\n",
    "print (\"True Matches:\",gt.shape[0])\n",
    "print (\"Correctly Matched:\",TP)\n",
    "print (\"Pair Completeness:\",PC)\n",
    "print (\"Recuction Ratio:\",RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Blocking for efficient data linkage\n",
    "# 2. For our blocking method, we choose to base on the price of the both datasets. We assign the blocks with each block having\n",
    "#  range of 50 dollar.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
